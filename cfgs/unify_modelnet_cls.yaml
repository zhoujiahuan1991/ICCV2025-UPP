optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.0005,
  weight_decay : 0.05
}}

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 300,
    initial_epochs : 10
}}

dataset : {
  train : { _base_: cfgs/dataset_configs/ModelNet40.yaml,
            others: {subset: 'train'}},
  val : { _base_: cfgs/dataset_configs/ModelNet40.yaml,
            others: {subset: 'test'}},
  test : { _base_: cfgs/dataset_configs/ModelNet40.yaml,
            others: {subset: 'test'}}}
model : {
  NAME: Point_MAE_unify,
  transformer_config: {
    mask_ratio: 0.5,
    mask_type: 'rand',
    trans_dim: 384,
    encoder_dims: 384,
    depth: 12,
    drop_path_rate: 0.1,
    num_heads: 6,
    decoder_depth: 4,
    decoder_num_heads: 6,
  },
  trans_dim: 384,
  depth: 12,
  drop_path_rate: 0.1,
  if_half: False,
  cls_dim: 40,
  num_heads: 6,
  group_size: 32,
  num_group: 64,
  encoder_dims: 384,
  adapter_config: {
    adapter_dim: 16,
    adapter_drop_path_rate: 0.1,
  },
  prompter_config: {
    rectify_adapter: True,
    rectify_prompts: True, 
    rectify_prompts_num: 3, 
    rectify_prompts_depth: 3,
    rectify_depth: 3,
    pretask_adapter: True,
    pretask_prompts: True, 
    pretask_prompts_num: 3, 
    pretask_prompts_depth: 6,
    pretask_depth: 6,
    downstream_adapter: True,
    downstream_prompts: True,
    downstream_prompts_num: 10, 
    downstream_prompts_depth: 6,
    downstream_depth: 12,
  },
  gather_idx: False,
  prompt_propagation_after: True
}


npoints: 1024
total_bs : 120 #320
step_per_update : 1
max_epoch : 300
grad_norm_clip : 10
task: 'classification'
data_augmentation: 'scale-translate'
noisy_train: True
noisy_validate: False